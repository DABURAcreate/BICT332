# -*- coding: utf-8 -*-
"""Lab1_222372907.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1T7fn3yUWE1J_OvlJUUZiHkC7GCfE8dmO
"""



"""# **Exercise 1: Testing imports**"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets
print("All packages imported successfully")

"""# **Exercise 2: Exploring Different Types of Learning (20 minutes)**

**Part A: Supervised Learning - Iris Classification bold text bold text**
"""

# Loading iris dataset
iris = datasets.load_iris()
X = iris.data
y = iris.target

# Exploring the dataset
print("Feature names:", iris.feature_names)
print("Target names:", iris.target_names)
print("First 5 samples:\n", X[:5])

#Simple visualization
plt.scatter(X[:, 0], X[:, 1], c = y)
plt.xlabel(iris.feature_names[0])
plt.ylabel(iris.feature_names[1])
plt.title("Iris Dataset")
plt.show()

"""Another"""

# Step 1: Importing Libraries
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd

# Step 2: Loading the Iris Dataset
iris = load_iris()
X = iris.data
y = iris.target

# Showing first few samples
df = pd.DataFrame(X, columns = iris.feature_names)
df['species'] = y
print("Sample Data")
print(df.head())

#Step 3: Split the Data (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Step 4: Train the Model (Logistic Regression)
model = LogisticRegression(max_iter = 200)
model.fit(X_train, y_train)

#Step 5: Make Predictions
y_pred = model.predict(X_test)

#Step 6: Evaluating the Model
print("\nAccuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names = iris.target_names))

"""**Part B: Unsupervised Learning - Iris Clustering**"""

from sklearn.cluster import KMeans

# Apply K-means clustering
kmeans = KMeans(n_clusters = 3)
kmeans.fit(X)
clusters = kmeans.predict(X)

# Compare with true labels
plt.scatter(X[:,0], X[:,1], c = clusters)
plt.xlabel(iris.feature_names[0])
plt.ylabel(iris.feature_names[1])
plt.title("K-means Clutering Results")
plt.show()

"""# **Exercise 3: The Machine Learing Pipeline**

---

**Step 1: Data Preparation**
"""

from sklearn.model_selection import train_test_split

# Split data into training and test set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)

print("Training set size:", X_train.shape)
print("Test set size:", X_test.shape)

"""**Step 2: Model Training**"""

from sklearn.neighbors import KNeighborsClassifier

# Creating and Training the model
model = KNeighborsClassifier(n_neighbors = 3)
model.fit(X_train, y_train)

"""**Step 3:Model Evaluation**"""

# Making predictions
y_pred = model.predict(X_test)

# Calculating accuracy
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_pred)
print(f"Model accuracy: {accuracy:.2f}")

"""# **Exercise 4: Reflection Questions**

1.  ** Observed differennce between supervised and unsupervised learning**:
In supervised learning, the LogisticRegression was used to train the model using labelled data. In other words, the model knew what outcome it should predict during training. For example, in the iris dataset, both X (iris.data) and y (iris.target) were used to train the model, so, it learned what species (setosa, versicolor, virginica) a new data instance must belong to based on their length and width.

In unsupervised learning, only the X (iris.data), not the y (iris.target) was used to train the data. So, the mode trained using KMeans did not know what species the instances belonged to. Meaning it used unlabelled data and clustered similar data together (This is shown clearly when we used **plt.show()**).

2.   **How train-test helped in evaluating the model**:
The train_test separated the data into a training set and a testing set. The model uses the training set to train to learn the relationship between features and label. Then the test set is used to evaluate how the model performs on new data.

The reason for the split, is to ensure that the model evaluates with data it has never seen before for accuracy purposes.

3.   **Factors that might affect the accuracy of the model?**
Choice of alorithms
Size of accurate (becomes limited)



4.  **Real World Applications**
For supervised learning: spam email filtering, medical diagnosis
For unsurvised learning: recommendation system (e.g., used in on Netflix)
"""